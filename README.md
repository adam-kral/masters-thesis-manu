# masters-thesis-manu

Abstract: Thermostability is key to successful protein engineering and therapeutic antibody development; accurate prediction accelerates the identification of stable proteins and the design of robust variants. This thesis evaluates zero-shot and supervised machine learning approaches for thermostability prediction, with a focus on antibodies. We achieve state-of-the-art performance on the public AbProp dataset—483&nbsp;antibodies with melting temperatures measured by differential scanning fluorimetry (DSF)—reaching a Spearman correlation of 0.49&nbsp;in the zero-shot setting and 0.69&nbsp;with supervised learning. We find that antibody-specific language models do not outperform general models in the zero-shot setting, which may be due to a wider distribution of thermostability in antibodies, resulting from possibly weaker evolutionary pressure for stability and the high variability introduced by their combinatorial V(D)J origin and somatic hypermutation. We further evaluate zero-shot generalization on the ProteinGym benchmark, showing that our models perform competitively on unrelated protein domains. We also analyze sequence positions contributing to supervised prediction and observe that antibodies with kappa light chains are, on average, more thermostable than those with lambda chains. Our results underscore the limitations of pretraining solely on antibody sequence data for zero-shot prediction. At the same time, they demonstrate that pretrained protein language models, which have previously been shown to perform well on general protein stability tasks, can also be successfully applied to antibody thermostability prediction in the zero-shot setting.

---

Current version of my master's thesis with errata fixed (since it's not possible to fix it in the university repository).

We fix: 1)&nbsp;result kappa light chain antibodies are more stable on average than lambda, where we originally switched kappa and lambda assignment due to a bug, 
2)&nbsp;the result for ZS3 score (AbProp holdout set SCC&nbsp;0.57 vs originally, in some parts, we report 0.58 which was for mistankenly cubing the individual score weights as in ZS4 score. However, the best on the train set for ZS3 was the identity, not cubing. The effect, though, is negligible), 3)&nbsp;several typos.
